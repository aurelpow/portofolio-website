---
layout: project
title: Yelp Batch ETL Pipeline â€” Business Analytics at Scale
thumb: /assets/img/project/yelp-batch-banner.png
date: 2025-11-26
permalink: /projects/yelp-batch-etl-pipeline/
repo: https://github.com/aurelpow/yelp-batch-pipeline
external_url: https://github.com/aurelpow/yelp-batch-pipeline
tags: [Data Engineering, Apache Spark, Scala, Airflow, MongoDB, Delta Lake, PostgreSQL, Docker, ETL Pipeline, Big Data]
---

A **batch ETL pipeline** that processes **9.3 GB of Yelp business data** to generate analytics and insights about business performance, customer reviews, and popularity trends.

Built with industry-standard tools for **big data processing**, **workflow automation**, and **data analytics** ğŸ“Š.

---

## ğŸ”‘ What This Project Does

- **Processes large-scale data**: Handles 9.3 GB across 5 datasets (150K+ businesses, 7M+ reviews, 2M+ tips)
- **3-layer data pipeline**: Raw data â†’ Cleaned data â†’ Business insights (Bronze â†’ Silver â†’ Gold)
- **Automated workflows**: Scheduled daily/monthly data processing with Apache Airflow
- **Business analytics**: Calculates popularity scores, rankings, and review metrics for every business
- **Production-ready**: Fully containerized with Docker, runs on any machine

---

## ğŸ—ï¸ How It Works
![yelp-pipeline]({{ '/assets/img/project/yelp-pipeline.png' | relative_url }})

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Data   â”‚â”€â”€â”€â”€â–¶â”‚    Bronze   â”‚â”€â”€â”€â”€â–¶â”‚    Silver    â”‚â”€â”€â”€â–¶â”‚     Gold    â”‚
â”‚  (9.3 GB)   â”‚     â”‚ (Raw Storage)â”‚     â”‚  (Cleaned)   â”‚     â”‚ (Analytics) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   JSON Files          Store as-is       Remove errors        Business KPIs
                                        Standardize data            â†“
                                                            PostgreSQL Database
```

**What happens at each layer:**
- **Bronze**: Raw data stored without changes (Parquet format)
- **Silver**: Data cleaned, validated, and organized (Delta Lake format)
- **Gold**: Final analytics ready for dashboards (PostgreSQL database)

---

## ğŸ“Š What Each Layer Does

### ğŸ¥‰ Bronze Layer â€” Store Raw Data
Saves all original data exactly as received, no changes. Stores 9.3 GB across 5 files:
- **Business data**: 150K+ businesses with locations, categories, ratings
- **Review data**: 7M+ customer reviews with ratings and text
- **Tip data**: 2M+ short tips from customers
- **Check-in data**: Visit frequency over time
- **User data**: Customer profiles and social connections

**Storage**: Parquet files (columnar format for fast queries)

### ğŸ¥ˆ Silver Layer â€” Clean & Organize
Fixes data quality issues and prepares data for analysis:
- Remove duplicate records
- Fix invalid values (e.g., ratings outside 1-5 range)
- Standardize text (uppercase states, trim spaces)
- Organize by date for time-based analysis

**Storage**: Delta Lake tables (supports updates and versioning)

### ğŸ¥‡ Gold Layer â€” Business Insights

**Business Popularity Score**
Ranks every business by calculating a weighted score from:
- Review ratings (30%)
- Number of reviews (25%)
- Check-in frequency (25%)
- Customer engagement (20%)

Output: Top businesses by city, updated monthly

**Review & Tip Metrics**
Daily and monthly statistics for each business:
- Total reviews, average stars, sentiment trends
- Tips received, compliments earned
- Growth trends over time

**Storage**: PostgreSQL database (ready for dashboards like Tableau, Power BI)

---

## ğŸ› ï¸ Technology Stack

### **Data Processing**
- **Apache Spark 3.5** â€” Big data processing engine
- **Scala 2.12** â€” Programming language (functional, type-safe)
- **SBT** â€” Build and dependency management

### **Workflow Automation**
- **Apache Airflow 3.0** â€” Orchestrates daily/monthly data processing
- **Python 3.12** â€” Airflow DAG definitions
- **Docker Compose** â€” Runs all services together

### **Data Storage**
- **Parquet** â€” Bronze layer (raw data storage)
- **Delta Lake 3.2** â€” Silver & Gold layers (supports versioning and updates)
- **PostgreSQL 13** â€” Final analytics database
- **MongoDB 7** (Optional) â€” Can load raw data from MongoDB instead of files

### **Deployment**
- **Docker** â€” Everything runs in containers (portable, reproducible)
- **Typesafe Config** â€” Manages different environments (local/dev/prod)

---

## âš™ï¸ Key Features

### ğŸ”„ **Flexible Processing**
- Process a single day, a date range, or specific tables only
- Run manually or schedule with Airflow
- Configurable for different environments (local, dev, production)

### ğŸ¯ **Data Quality**
- Validates data quality at every step
- Removes duplicates automatically
- Handles missing or invalid data
- Safe to re-run without corrupting data

### ğŸ“ˆ **Performance**
- Processes 9.3 GB of data efficiently using distributed computing
- Stores data in optimized formats for fast queries
- Organizes data by date for time-series analysis

---

## ğŸš€ How to Run

### **Requirements**
- Docker (to run all services)
- 10 GB free disk space
- Download Yelp dataset from Kaggle (9.3 GB)

### **Quick Start**

1. Clone the repository
2. Download Yelp dataset and place in `data/raw/`
3. Build the application: `sbt clean assembly`
4. Start services: `docker-compose up -d`
5. Access Airflow UI at `http://localhost:8080`
6. Configure Spark connection in Airflow
7. Trigger the pipeline from the UI

The pipeline runs automatically based on schedule, or you can trigger it manually for specific dates.

---

## ğŸ“Š Sample Outputs

### **Business Popularity Rankings**
```sql
SELECT name, city, state, popularity_score, city_rank
FROM gold.business_popularity
WHERE period_month = '2020-01' AND city = 'Philadelphia'
ORDER BY city_rank
LIMIT 5;
```

| name | city | state | popularity_score | city_rank |
|------|------|-------|------------------|-----------|
| Terakawa Ramen | Philadelphia | PA | 0.7212 | 1 |
| Vedge Restaurant | Philadelphia | PA | 0.6954 | 2 |
| Zahav | Philadelphia | PA | 0.6823 | 3 |

### **Daily Review Metrics**
```sql
SELECT day, measure, SUM(units) as total
FROM gold.fact_review_tip_metrics_wide
WHERE business_id = 'ABC123' AND granularity = 0
GROUP BY day, measure
ORDER BY day DESC;
```

---

## ğŸ”® Future Enhancements

- **Machine Learning** â€” Sentiment analysis on review text
- **Interactive dashboards** â€” Build visualizations with Tableau or Power BI
- **Cloud deployment** â€” Deploy on AWS,Azure or GCP for scalability
- **Advanced analytics** â€” Predictive models for business trends

---

## ğŸ“ Project Structure

```
yelp-batch-project/
â”œâ”€â”€ src/main/scala/com/yelpbatch/
â”‚   â”œâ”€â”€ app/                    # Entry point (Runner.scala)
â”‚   â”œâ”€â”€ bronze/                 # Raw ingestion layer
â”‚   â”œâ”€â”€ silver/                 # Cleaned transformation layer
â”‚   â”œâ”€â”€ gold/                   # Analytics aggregation layer
â”‚   â”‚   â”œâ”€â”€ businesspopularity/ # Popularity score computation
â”‚   â”‚   â””â”€â”€ factreviewtip/      # Review & tip metrics
â”‚   â””â”€â”€ utils/                  # Common utilities (IOUtils, DateUtils, etc.)
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/                   # Airflow DAG definitions
â”‚   â”œâ”€â”€ jars/                   # Spark application JAR
â”‚   â””â”€â”€ config/                 # Airflow configuration
â”œâ”€â”€ sql/                        # PostgreSQL schema definitions
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Source JSON files (9.3 GB)
â”‚   â”œâ”€â”€ bronze/                 # Raw Parquet files
â”‚   â”œâ”€â”€ silver/                 # Delta Lake tables
â”‚   â””â”€â”€ gold/                   # Gold Delta tables (pre-PostgreSQL)
â”œâ”€â”€ docker-compose.yaml         # Multi-container orchestration
â””â”€â”€ build.sbt                   # Scala build definition
```

---

## ğŸ“ Skills Demonstrated

âœ… **Data Engineering** â€” ETL pipeline design, data quality, multi-layer architecture  
âœ… **Big Data Processing** â€” Apache Spark for distributed computing at scale  
âœ… **Programming** â€” Scala (functional programming), Python (automation)  
âœ… **Workflow Orchestration** â€” Apache Airflow for scheduling and monitoring  
âœ… **Databases** â€” PostgreSQL (analytics), Delta Lake (versioning), MongoDB (NoSQL)  
âœ… **DevOps** â€” Docker containerization, multi-service orchestration  
âœ… **Data Modeling** â€” Analytics tables, KPIs, business metrics  

---

## ğŸ“œ License

This project is licensed under the MIT License.

---

## ğŸ”— Links

- **GitHub Repository**: [yelp-batch-pipeline](https://github.com/aurelpow/yelp-batch-pipeline)
- **Dataset Source**: [Yelp Open Dataset (Kaggle)](https://www.kaggle.com/datasets/yelp-dataset/yelp-dataset/)
- **Documentation**: See `/README.md` and `/sql/README.md`

---

**Built with â¤ï¸ by [AurÃ©lien](https://github.com/aurelpow)**

